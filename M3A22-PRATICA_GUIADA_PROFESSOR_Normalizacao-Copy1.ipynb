{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OnEkfJXQsyY"
   },
   "source": [
    "# PRÁTICA GUIADA: Normalização de dados com Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos trabalhar com o dataset de preços de imóveis da cidade de Bostn, conhecido como:\n",
    "\n",
    "Boston house prices dataset\n",
    "---------------------------\n",
    "\n",
    "**Data Set Characteristics:**  \n",
    "\n",
    "    :Number of Instances: 506 \n",
    "\n",
    "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
    "\n",
    "    :Attribute Information (in order):\n",
    "        - CRIM     per capita crime rate by town\n",
    "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "        - INDUS    proportion of non-retail business acres per town\n",
    "        - CHAS     Charles River dummy Variável (= 1 if tract bounds river; 0 otherwise)\n",
    "        - NOX      nitric oxides concentration (parts per 10 million)\n",
    "        - RM       average number of rooms per dwelling\n",
    "        - AGE      proportion of owner-occupied units built prior to 1940\n",
    "        - DIS      weighted distances to five Boston employment centres\n",
    "        - RAD      index of accessibility to radial highways\n",
    "        - TAX      full-value property-tax rate per USD10,000\n",
    "        - PTRATIO  pupil-teacher ratio by town\n",
    "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "        - LSTAT    % lower status of the population\n",
    "        - MEDV     Median value of owner-occupied homes in USD 1000's\n",
    "\n",
    "    :Missing Attribute Values: None\n",
    "\n",
    "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
    "\n",
    "This is a copy of UCI ML housing dataset.\n",
    "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
    "\n",
    "\n",
    "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
    "\n",
    "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
    "prices and the demand for clean air', J. Environ. Economics & Management,\n",
    "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
    "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
    "pages 244-261 of the latter.\n",
    "\n",
    "The Boston house-price data has been used in many machine learning papers that address regression\n",
    "problems.   \n",
    "     \n",
    ".. topic:: References\n",
    "\n",
    "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
    "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para explorarmos o dataset vamos habilihar a [função mágica](https://ipython.readthedocs.io/en/stable/interactive/magics.html)  [`%matplotlib inline`](https://www.it-swarm.dev/pt/python/objetivo-do-matplotlib-inline/831339552/), para plotarmos nossos gráficos em tela.\n",
    "\n",
    "#### Vamos precisar importar as seguintes bibliotecas:\n",
    "\n",
    "- [`matplotlib.pyplot`](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.html), para gráficos.\n",
    "- [`numpy`](numpy.org), para o manejo dos dados.\n",
    "- [`pandas`](https://pandas.pydata.org/), para o manejo dos dados.\n",
    "- [`sklearn.datasets`](https://scikit-learn.org/stable/datasets/index.html) para a otenção de um dataset.\n",
    "- [`sklearn.linear_model`](https://scikit-learn.org/stable/modules/linear_model.html), para a modelização dos dados.\n",
    "- [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/preprocessing.html), para o pre-processamento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Em seguida podemos carregar o conjunto de dados de Boston, para isso usamos a função [`datasets.load_boston()`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html) e carregamos o mesmo em um objetp `boston`. \n",
    "\n",
    "#### Repare que o objeto `boston` é do tipo [`sklearn.utils.Bunch`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.Bunch.html), um objeto Container que expõe chaves como atributos, o que significa que temos que aplicar o atributo [`.data`](https://scikit-learn.org/0.16/modules/generated/sklearn.datasets.load_boston.html) para acessar os dados do dataset.\n",
    "\n",
    "#### A observação anterior se torna relevante quando a função [`pd.DataFrame`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) for usada para converter o container `boston` no dataframe `df`.\n",
    "\n",
    "\n",
    "\n",
    "#### O atributo [`feature_names`](https://subscription.packtpub.com/book/big_data_and_business_intelligence/9781789537864/1/ch01lvl1sec13/datasets-and-code-used-in-this-book) pode ser útil para extrair o nome dos atributos do objeto `bunch`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "print (boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "df = pd.DataFrame(boston.data, \n",
    "                  columns = boston.feature_names\n",
    "                 )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Z0jhspIQsyj"
   },
   "source": [
    "### Normalizamos os dados\n",
    "\n",
    "#### Vejamos o efeito de escalar os dados escolhendo um par de variáveis com uma grande diferença de escala."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Os atributos de `NOX` para concentração de oxido nitroso e `TAX` para o valor total dos impostos cobrados têm unidades diferentes e escalas distintas.\n",
    "\n",
    "#### Vamos instanciar os objetos `xs` e `ys` para receber os atributos acima e plotar a dispersão [`plt.scatter()`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) de ambos os atributos e observar as escalas relacionadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "\n",
    "plt.scatter(xs, ys)\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C4R7exWIQsyo"
   },
   "source": [
    "### Padronização\n",
    "\n",
    "#### Vamos aplicar a [padronização](https://towardsdatascience.com/normalization-vs-standardization-explained-209e84d0f81e) e transformar as variáveis para terem média 0 $(\\mu = 0)$ e desvio padrão 1 $(\\sigma = 1)$ aplicando a fórmula: <br/>\n",
    "<br/>\n",
    "<center>$ x' = \\frac{x - \\mu}{\\sigma}$</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para tanto vamos novamente instanciar os atributos `NOX` e `TAX` com os objetos `xs` e `ys` e calcular seus valores médios, com a função [`np.mean()`](https://numpy.org/doc/stable/reference/generated/numpy.mean.html), e seus desvios padrões com a função [`np.std()`](https://numpy.org/doc/stable/reference/generated/numpy.std.html).\n",
    "\n",
    "#### Podemos replotar o gráfico anterior, atualizar os valores de `xs` e `ys` e plotar uma dispersão atualizada com a normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "\n",
    "plt.scatter(xs, ys, color = 'b')\n",
    "\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## escreva a função para normalizar os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fazer o histograma das variáveis normalizadas e não normalizadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_TB5Rr0yQsyz"
   },
   "source": [
    "#### Como se pode ver, não alteramos a forma dos dados, só sua escala. Também podemos usar scikit-learn para padronizar variáveis.\n",
    "\n",
    "#### Para isso vamos fazer uso da classe de funções [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) e especificamente da função [`preprocessing.scale()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html). Usaremos também a função `plt.scatter()` para a dispersão dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "xs = preprocessing.scale(df[\"NOX\"])\n",
    "ys = preprocessing.scale(df[\"TAX\"])\n",
    "\n",
    "plt.scatter(xs, ys, color = 'r')\n",
    "plt.xlabel(\"NOX standardized\")\n",
    "plt.ylabel(\"TAX standardized\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#observação importante ## boas práticas\n",
    "# https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(x_test.values)\n",
    "\n",
    "x_train_norm = scaler.transform(x_train.values)\n",
    "x_test_norm = scaler.transform(x_test.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Agora considere que tivermos muitos outliers? como fazer? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style = \"color:blue\">Prática Independente 1.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe os atributos de taxa de criminalidade per capita `CRIM` e distâncias ponderadas para cinco centros de emprego em Boston `DIS` do dataset e plote uma dispersão inicial dessas colunas.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora calcule a padronização, criando uma função específica, para então realizar a plotagem da padroniação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faça o plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Você encontrou valores negativos para sua padronização? o que eles significam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplique a função `preprocessing.scale()` da biblioteca `sklearn` e compare a padronização automática da biblioteca com aquela que você calculou com a função que criou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A seguir plote as distribuições para as formas originais e padronizadas de `DIS` e `CRIM` e observe se a padronização gerou algum efeito indesejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKR8Jl0fQsy3"
   },
   "source": [
    "### Normalização Min-Max\n",
    "\n",
    "#### Vamos testar agora essa outra forma de normalização aplicando a seguinte fórmula: <br/>\n",
    "<br/>\n",
    "<center>$x' = \\frac{x - x_{min}}{x_{max} - x_{min}}$<center/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uma outra forma de aplicarmos uma domalização aos dados é pelo método dos [mínimos e máximos](https://towardsdatascience.com/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79). \n",
    "\n",
    "#### Para isso vamos precisar fazer uso das funções  [`np.min()`](https://numpy.org/doc/stable/reference/generated/numpy.minimum.html) [`np.max()`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.max.html) para calcular os valores mínimos e máximos de dos atributos `'NOX'` e `'TAX'`, que separamos.\n",
    "\n",
    "#### Depois da atualização dos valores de `xs` e `ys` podemos com a relação que vimos acima na célula anterior, podemos plotar as dispersões, com a ajuda da função `plt.scatter()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotamos a seguir a dispersão dos atributos escolhidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df[\"NOX\"]\n",
    "ys = df[\"TAX\"]\n",
    "plt.scatter(xs, \n",
    "            ys, \n",
    "            color = 'b')\n",
    "plt.xlabel(\"NOX\")\n",
    "plt.ylabel(\"TAX\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vamos normalizaar dos atributos escolhidos, a partir dos métodos de máximo e mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "y1VBmCkJQsy4"
   },
   "source": [
    "#### Plotamos agora os dados normalizados pelo método Min-Max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Se checarmos novamente os histogramas para os casos com e sem a regularização por (Mín-Máx) veremos novamente que o processo de normalização não afeta as distribuições dos atributos.\n",
    "\n",
    "#### Podemos repetir os processos de definição do tamanho da figura, com a função`plt.figure()`, posicionamento dos subplots com `plt.subplot()` e  os títulos de cada histograma, com `.set_title()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HpmdtCSBQszG"
   },
   "source": [
    "#### Esse tipo de normalização também pode ser obtido com scikit-learn, com a classe de funções [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/preprocessing.html) podemos \n",
    "\n",
    "\n",
    "#### [`preprocessing.MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) que dimensiona e converte cada recurso individualmente de modo que esteja no intervalo especificado no conjunto de treinamento, por exemplo entre zero e um.\n",
    "\n",
    "\n",
    "#### Depois disso vamos aplicar a função [`scaler.fit_transform()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler.fit_transform) que ajusta os dados e depois os transforma, retornando uma versão transformada do `X`, para atualizar os valores de `xs` e `ys`.\n",
    "\n",
    "#### Por fim plotamos a nova dispersão com [`plt.scatter()`](https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html) para os dados normalizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "xs = scaler.fit_transform(df[[\"NOX\"]])\n",
    "ys = scaler.fit_transform(df[[\"TAX\"]])\n",
    "\n",
    "plt.scatter(xs, ys, color='r')\n",
    "plt.xlabel(\"NOX Min-Max Scaled\")\n",
    "plt.ylabel(\"TAX Min-Max Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style = \"color:blue\">Prática Independente 2.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe os atributos de taxa de criminalidade per capita `CRIM` e distâncias ponderadas para cinco centros de emprego em Boston `DIS` do dataset e plote uma dispersão inicial dessas colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crie uma função que gere a normalização pelo método  de quaisquer dois atributos informados como parâmetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agora plote uma nova dispersão dos mesmos atributos submetidos à normalização e discuta o que vê."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plote as distribuições dos atributos `xs` e `ys` estudados acima, para os valores antes e depois da normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Por fim, faça uso da função [`.MinMaxScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) para normalizar os atributos escolhidos e os compare com a função que você criou anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "xs = scaler.fit_transform(df[[\"DIS\"]])\n",
    "ys = scaler.fit_transform(df[[\"CRIM\"]])\n",
    "\n",
    "plt.scatter(xs, ys, color = 'g')\n",
    "plt.xlabel(\"DIS Min-Max Scaled\")\n",
    "plt.ylabel(\"CRIM Min-Max Scaled\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <span style = \"color:blue\">Prática Independente 3.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estude a dispersão entre os atributos `DIS` e `CRIM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df[\"DIS\"]\n",
    "ys = df[\"CRIM\"]\n",
    "plt.scatter(xs, \n",
    "            ys, \n",
    "            color = 'b')\n",
    "plt.xlabel(\"DIS\")\n",
    "plt.ylabel(\"CRIM\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crie uma função capaz de realizar ambas as normalizações `L1` e `L2`, a partir de parâmetros de identificação dos atributos `xs` e `ys` e do tipo de norealizadarealizadarmalização a ser realizada.\n",
    "\n",
    "1. L1 o valor é dividido pela soma dos valores absolutos\n",
    "2. L2 o valor ẽ dividido pela soma dos valoes ao quadrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Escreva a função"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplique a normalização `L1` na função que você criou no item anterior, para os atributos `DIS` e `CRIM` e plote sua dispersão normalizada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A escala do scatterplot fica muito pequena com L1 e é impossível de visualizar.\n",
    "# Pode-se testar a multiplicação de cada vetor por 100 para conferir se a forma dos dados permanece inalterada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare as distribuições para `DIS` e `CRIM`, antes de depois da normalização."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repita para os mesmos atributos `DIS` e `CRIM` os procedimentos anteriores, agora para a normalização do tipo `L2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A escala do scatterplot fica muito pequena com L1 e é impossível de visualizar.\n",
    "# Pode-se testar a multiplicação de cada vetor por 100 para conferir se a forma dos dados permanece inalterada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "PRACTICA_GUIADA_Normalización_pt_br.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
